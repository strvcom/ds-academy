
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Lecture 4: Model Improvements and Pipelines &#8212; Data Science Academy</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://strvcom.github.io/ds-academy/intro.html/lectures/04_lecture/data_pipelines.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Evaluating, comparing, and selecting ML models" href="../05_lecture/intro.html" />
    <link rel="prev" title="Let’s build our first data pipeline!" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science Academy</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome, AI/ML enthusiast
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../00_start/intro.html">
   Getting Started
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_start/git.html">
     Git and GitHub
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_start/environment-setup.html">
     Setup Environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_start/notebooks.html">
     Getting started with Jupyter Notebooks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_start/ide-overview.html">
     Getting more done with IDEs
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Your Hands Dirty with Basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01_lecture/intro.html">
   Getting Your Hands Dirty with Basics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_lecture/python_basics.html">
     Python Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_lecture/motivational_example.html">
     Motivational Example
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Understanding, Extracting, Sourcing and Processing Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02_lecture/intro.html">
   Understanding, Extracting, Sourcing and Processing Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_lecture/numpy_basics.html">
     Introduction to NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_lecture/pandas_basics.html">
     Introduction to Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_lecture/matplotlib_basics.html">
     Visualization with Matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_lecture/acquiring_data.html">
     Acquiring Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_lecture/eda.html">
     Exploratory Data Analysis (EDA) Wine Quality dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_lecture/data_preparation.html">
     Data Preparation for ML
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  AI/ML Basic Concepts
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03_lecture/intro.html">
   Let’s learn some ML concepts and do some regression!
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_lecture/supervised_unsupervised_learning.html">
     Lecture 3: ML Models
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data Pipelines
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Let’s build our first data pipeline!
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Lecture 4: Model Improvements and  Pipelines
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Evaluating, comparing, and selecting ML models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05_lecture/intro.html">
   Evaluating, comparing, and selecting ML models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_lecture/model_evaluation.html">
     Model evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_lecture/model_selection.html">
     Model selection
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/strvcom/ds-academy/master?urlpath=tree/lectures/04_lecture/data_pipelines.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/strvcom/ds-academy"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/strvcom/ds-academy/issues/new?title=Issue%20on%20page%20%2Flectures/04_lecture/data_pipelines.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/lectures/04_lecture/data_pipelines.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Lecture 4: Model Improvements and  Pipelines
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-pipeline">
   Data Pipeline
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     LOGISTIC REGRESSION
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest">
     RANDOM FOREST
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#neural-network">
     Neural Network
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wine-dataset">
   WINE DATASET
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-practice-mnist-dataset">
   IN PRACTICE: MNIST DATASET
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-bonus-tutorial">
   Exercise / bonus tutorial
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Lecture 4: Model Improvements and  Pipelines</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Lecture 4: Model Improvements and  Pipelines
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-pipeline">
   Data Pipeline
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     LOGISTIC REGRESSION
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest">
     RANDOM FOREST
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#neural-network">
     Neural Network
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wine-dataset">
   WINE DATASET
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-practice-mnist-dataset">
   IN PRACTICE: MNIST DATASET
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-bonus-tutorial">
   Exercise / bonus tutorial
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="lecture-4-model-improvements-and-pipelines">
<h1>Lecture 4: Model Improvements and  Pipelines<a class="headerlink" href="#lecture-4-model-improvements-and-pipelines" title="Permalink to this headline">#</a></h1>
<p>In this lecture we are going to build upon the knowledge of last week(s). We will combine data preprocessing steps with ML models and crete data pipelines. In addition, a few tips of model improvements (class imbalance) will be discussed.</p>
<p>This week you will learn:</p>
<ul class="simple">
<li><p>Something about Random-forest and deep learning.</p></li>
<li><p>How to combine data-preprocessing and modelling in a data pipeline.</p></li>
<li><p>How to use different models on a given, practical problem.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">generate_dataset</span> <span class="kn">import</span> <span class="n">generate_dataset</span>
</pre></div>
</div>
</div>
</div>
<p>To illustrate where we currrently are I am reposing the schema below from last week. Un this class we will zoom in further on classification.</p>
<p><img alt="alt text" src="../../_images/0002.jpg" /></p>
<p>In this lecture we will discuss and apply several ML-algorithms.</p>
<p>The main models of this lecture are:</p>
<ul class="simple">
<li><p>Logistic Regression (see previous lecture)</p></li>
<li><p>Random Forest (a decision tree)</p></li>
<li><p>Neural Network</p></li>
</ul>
<p>I will briefly discuss them.</p>
<p>The slide below was shown in last week’s presentation. A reminder that logistic regression is a linear classifier.</p>
<img src ="../../static/images/03_lecture/0008.jpg" width="1000" heigth="200" />
<p>The second model is the Random Forest, which is basically a collection of decision trees. A classical decision tree is shown below. The question is “should I play badminton?”</p>
<img src ="../../static/images/04_lecture/decision_tree.png" width="1000" heigth="200" />
<p>A single decision tree is unstable. For this reason we generate many of them and then average the predictions. A Random Forest is not a linear classifier and can thus be vary useful.</p>
<img src ="../../static/images/04_lecture/random_forest.png" width="1000" heigth="200" />
<p>And finally we will use Neural Networks. The image below shows a single hidden layer, but the number of hidden layers can ofcource vary (deep learning). The mathematical idea is that we can fit almost every function by just adding hidden layers. The more layers we add, the more complex our functions can become. This allowed for lost of breakthroughs in many fields (e.g. computer vision and NLP) in the last ten years.</p>
<img src ="../../static/images/04_lecture/perceptron.png" width="1000" heigth="200" />
</section>
<section id="data-pipeline">
<h1>Data Pipeline<a class="headerlink" href="#data-pipeline" title="Permalink to this headline">#</a></h1>
<p>To illustrate the use of data pipelines, we are going to generate data using a function that I created (see generate_dataset.py). The task will be a classification task and will contain both numerical and categorical features. Unlike last we week, we will use the sklearn function make_classification to generate our data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">secrets</span> <span class="kn">import</span> <span class="n">choice</span>


<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">generate_dataset</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>For our data pipeline, we need to know which features are categorical or numerical. Both types of variables require different steps in the preprocessing pipeline. Categorical features need to be numerically encoded (e.g: 1h-encoding). Numerical features need (in many cases) to be standardized (see lecture 2).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">categorical_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="s1">&#39;categorical&#39;</span> <span class="ow">in</span> <span class="n">column</span><span class="p">]</span>
<span class="n">numerical_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="s1">&#39;numerical&#39;</span> <span class="ow">in</span> <span class="n">column</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We will now create a pipeline using ColumnTransformer and Pipeline from sklearn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create ColumnTransformer, and pass the column names to transform in each step</span>

<span class="k">def</span> <span class="nf">make_pipeline</span><span class="p">(</span><span class="n">categorical_cols</span><span class="o">=</span><span class="p">[],</span> <span class="n">numerical_cols</span><span class="o">=</span><span class="p">[],</span> <span class="n">classifier</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">()):</span>
    <span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">(</span><span class="s1">&#39;ohe&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">),</span> <span class="n">categorical_cols</span><span class="p">),</span>
            <span class="p">(</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">numerical_cols</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
        <span class="n">steps</span><span class="o">=</span><span class="p">[</span>
            <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
            <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">clf</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have defined our pipeline, let’s see how different models will perform on our generated data. We define the models that we want to test in the list below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">models_to_run</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">80</span><span class="p">),</span>
    <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="mi">6</span><span class="p">),</span>
    <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span>
    <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="p">]</span>
    
</pre></div>
</div>
</div>
</div>
<p>The standard classification metric to evaluate models in sklearn pipelines is the Accuracy. The Accuracy is the number of correct predictions out of all the datapoints. This metric works ok in generic situations, but might not be the best in cases where the distribution of the target, y, is not even. This situation is normally referred to as <strong>unbalanced</strong>.</p>
<p>We will quickly assess our target distribution to see if it is balancef or unbalanced before we continue.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">pie</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>([&lt;matplotlib.patches.Wedge at 0x7f6844214cd0&gt;,
  &lt;matplotlib.patches.Wedge at 0x7f684422a190&gt;,
  &lt;matplotlib.patches.Wedge at 0x7f684422a610&gt;],
 [Text(0.5460048198287359, 0.9549234192980031, &#39;0&#39;),
  Text(-1.0999131482721833, 0.013822671882601915, &#39;1&#39;),
  Text(0.5339620793196749, -0.9617091544997424, &#39;2&#39;)])
</pre></div>
</div>
<img alt="../../_images/data_pipelines_25_1.png" src="../../_images/data_pipelines_25_1.png" />
</div>
</div>
<p>The distribution is approximately even, so the Accuracy will suffice. We will now run the models on our data, store the clasification results (the Accuracy!) and show them using a pandas dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models_to_run</span><span class="p">:</span>

    <span class="c1"># create instance of the class, feed the model to be tested</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">categorical_cols</span><span class="p">,</span> <span class="n">numerical_cols</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># store results in a dictionary </span>
    <span class="n">results</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="p">)]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LogisticRegression(multi_class='multinomial')</th>
      <td>0.668</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(max_depth=2)</th>
      <td>0.708</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(max_depth=5)</th>
      <td>0.824</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(max_depth=10)</th>
      <td>0.844</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(max_depth=20)</th>
      <td>0.828</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(max_depth=80)</th>
      <td>0.848</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=2)</th>
      <td>0.296</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=6)</th>
      <td>0.772</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=10)</th>
      <td>0.820</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=20)</th>
      <td>0.832</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=40)</th>
      <td>0.840</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>There are big differences between the performances, but the random forest and the neural network seem to be the big winners. Clearly, there is something to gain from upgrading from the simple logstic regression to RF or NN. So what exactly are the the weak/strong points of these algorithm and how do we know when to use which one?</p>
<section id="logistic-regression">
<h2>LOGISTIC REGRESSION<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Advantages: interpretable results and should be used in cases where you want to understand relationships.</p></li>
<li><p>Disadvantages: often not able to capture complex/relationships and doesn’t work well out of the box if non-linearities are present.</p></li>
</ul>
</section>
<section id="random-forest">
<h2>RANDOM FOREST<a class="headerlink" href="#random-forest" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Advantages: works very well out of the box. Is resilient against overfitting and is able to capture complex (non-linear) relationships. Almost no data-preprocessing is needed!</p></li>
<li><p>Disadvantages: there are many hyperparamers to tune, not as interpretable as logistic regression.</p></li>
</ul>
</section>
<section id="neural-network">
<h2>Neural Network<a class="headerlink" href="#neural-network" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Advantages: can theoretically model any relation. Can lead to very high results, IF tuned properly.</p></li>
<li><p>Disadvantages: very easy to overfit, designing a model can take a long time, almost no interpretability.</p></li>
</ul>
</section>
</section>
<section id="wine-dataset">
<h1>WINE DATASET<a class="headerlink" href="#wine-dataset" title="Permalink to this headline">#</a></h1>
<p>So, let’s see how well our pipeline will perform on some real-world examples. Our first stop is the famous ‘wine’ dataset, where we ought to predict the quality of wines given several features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wine</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../../static/data/winequality-red.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_wine</span> <span class="o">=</span> <span class="n">wine</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span>
<span class="n">X_wine</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;quality&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This dataset is actually a regression problem, but we will change it into a classification problem by grouping the target. We will create two groups: ‘medium’ with all rating up to and including 6, and ‘excellent’ containg all ratings from 7.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create Classification version of target variable</span>
<span class="n">y_wine</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">7</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">y_wine</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_wine</span> <span class="o">=</span> <span class="n">y_wine</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;medium&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;excellent&#39;</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<p>So what do our features look like?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_wine</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fixed acidity</th>
      <th>volatile acidity</th>
      <th>citric acid</th>
      <th>residual sugar</th>
      <th>chlorides</th>
      <th>free sulfur dioxide</th>
      <th>total sulfur dioxide</th>
      <th>density</th>
      <th>pH</th>
      <th>sulphates</th>
      <th>alcohol</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7.4</td>
      <td>0.70</td>
      <td>0.00</td>
      <td>1.9</td>
      <td>0.076</td>
      <td>11.0</td>
      <td>34.0</td>
      <td>0.9978</td>
      <td>3.51</td>
      <td>0.56</td>
      <td>9.4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7.8</td>
      <td>0.88</td>
      <td>0.00</td>
      <td>2.6</td>
      <td>0.098</td>
      <td>25.0</td>
      <td>67.0</td>
      <td>0.9968</td>
      <td>3.20</td>
      <td>0.68</td>
      <td>9.8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.8</td>
      <td>0.76</td>
      <td>0.04</td>
      <td>2.3</td>
      <td>0.092</td>
      <td>15.0</td>
      <td>54.0</td>
      <td>0.9970</td>
      <td>3.26</td>
      <td>0.65</td>
      <td>9.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11.2</td>
      <td>0.28</td>
      <td>0.56</td>
      <td>1.9</td>
      <td>0.075</td>
      <td>17.0</td>
      <td>60.0</td>
      <td>0.9980</td>
      <td>3.16</td>
      <td>0.58</td>
      <td>9.8</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7.4</td>
      <td>0.70</td>
      <td>0.00</td>
      <td>1.9</td>
      <td>0.076</td>
      <td>11.0</td>
      <td>34.0</td>
      <td>0.9978</td>
      <td>3.51</td>
      <td>0.56</td>
      <td>9.4</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Do we have any categorical feature hiding in our dataset that we would want to one-hot-encode with our pipeline?</p>
<p>Remember that a categorical feature often has a low number of unique values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_wine</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fixed acidity            96
volatile acidity        143
citric acid              80
residual sugar           91
chlorides               153
free sulfur dioxide      60
total sulfur dioxide    144
density                 436
pH                       89
sulphates                96
alcohol                  65
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Thw output above shows the number of unique values per feature. If the number of unique values is low, it could be an indication that it is better to treat the variable as <code class="docutils literal notranslate"><span class="pre">categorical</span></code> (make them a string).</p>
<p>The dataset has a total of 1600 rows (or observations), so in this case I would say that it is ok to treat all the variables as numerical.</p>
<p>For class balance we have to plot the distribution of the target again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels_wine</span><span class="p">,</span> <span class="n">counts_wine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_wine</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">pie</span><span class="p">(</span><span class="n">counts_wine</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_wine</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels_wine</span><span class="p">,</span> <span class="n">autopct</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%1.1f%%</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of wine labels&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/data_pipelines_43_0.png" src="../../_images/data_pipelines_43_0.png" />
</div>
</div>
<p>The distribution of the labels is a off. It means that we can get 86% accuracy by always predicting ‘medium’. Therefor we need a metric that somehow corrects for this. We find our corrected metric in someone called the ‘F1 score’. We will also try to ‘fix’ the class imbalance by adding a parameter to our pipeline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_wine</span><span class="p">,</span> <span class="n">X_test_wine</span><span class="p">,</span> <span class="n">y_train_wine</span><span class="p">,</span> <span class="n">y_test_wine</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_wine</span><span class="p">,</span> <span class="n">y_wine</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">.50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We dont have categorical features in our dataset, so we dont need to process them. We standardize all of our features!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">categorical_cols</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">numerical_cols</span> <span class="o">=</span> <span class="n">X_train_wine</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models_to_run</span><span class="p">:</span>

    <span class="c1"># create instance of the class, feed the model to be tested</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">categorical_cols</span><span class="p">,</span> <span class="n">numerical_cols</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_wine</span><span class="p">,</span> <span class="n">y_train_wine</span><span class="p">)</span>

    <span class="c1"># store results in a dictionary </span>
    <span class="n">results</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="p">)]</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_wine</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_wine</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LogisticRegression(multi_class='multinomial')</th>
      <td>0.868228</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(max_depth=2)</th>
      <td>0.813091</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(max_depth=5)</th>
      <td>0.881106</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(max_depth=10)</th>
      <td>0.893475</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(max_depth=20)</th>
      <td>0.898869</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(max_depth=80)</th>
      <td>0.902636</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=2)</th>
      <td>0.813091</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=6)</th>
      <td>0.861932</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=10)</th>
      <td>0.864113</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=20)</th>
      <td>0.868115</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=40)</th>
      <td>0.875574</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>An interesting observation is that the Neural Network does not seem to do much better than the Random Forest. Ofcourse, this might be different with proper hyperparameter tuning (see next week!), but something else must be mentioned. On tabular data (data that fit into an excel spreadsheet), Neural Networks might not be the best choice. A Random Forest, on the other hand, tends to have a good performance on tabular data.</p>
<p>Our minority class (excellent wines!) only has an occurence of 13%. Luckily there is a trick in sklearn’s random forest algorithm, a single parameter that we can use in order to correct for this. This parameter is called <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> and we want to set it to <code class="docutils literal notranslate"><span class="pre">balanced</span></code> in order to tackle class imbalance.</p>
<p>It to our pipeline we do this as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create ColumnTransformer, and pass the column names to transform in each step</span>

<span class="k">def</span> <span class="nf">make_pipeline</span><span class="p">(</span><span class="n">categorical_cols</span><span class="o">=</span><span class="p">[],</span> <span class="n">numerical_cols</span><span class="o">=</span><span class="p">[],</span> <span class="n">classifier</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">()):</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">):</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="s1">&#39;class_weight&#39;</span><span class="p">,</span> <span class="s1">&#39;balanced&#39;</span><span class="p">)</span>

    <span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">(</span><span class="s1">&#39;ohe&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">),</span> <span class="n">categorical_cols</span><span class="p">),</span>
            <span class="p">(</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">numerical_cols</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
        <span class="n">steps</span><span class="o">=</span><span class="p">[</span>
            <span class="p">(</span><span class="s1">&#39;preprocessor&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
            <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">clf</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models_to_run</span><span class="p">:</span>

    <span class="c1"># create instance of the class, feed the model to be tested</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">categorical_cols</span><span class="p">,</span> <span class="n">numerical_cols</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_wine</span><span class="p">,</span> <span class="n">y_train_wine</span><span class="p">)</span>

    <span class="c1"># store results in a dictionary </span>
    <span class="n">results</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="p">)]</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_wine</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_wine</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.
  warnings.warn(
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LogisticRegression(multi_class='multinomial')</th>
      <td>0.868228</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(class_weight='balanced', max_depth=2)</th>
      <td>0.827921</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(class_weight='balanced', max_depth=5)</th>
      <td>0.861615</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(class_weight='balanced', max_depth=10)</th>
      <td>0.895271</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(class_weight='balanced', max_depth=20)</th>
      <td>0.897075</td>
    </tr>
    <tr>
      <th>RandomForestClassifier(class_weight='balanced', max_depth=80)</th>
      <td>0.898138</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=2)</th>
      <td>0.841751</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=6)</th>
      <td>0.847798</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=10)</th>
      <td>0.867442</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=20)</th>
      <td>0.872352</td>
    </tr>
    <tr>
      <th>MLPClassifier(hidden_layer_sizes=40)</th>
      <td>0.882180</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Unfortunately the parameter did not change our model for the better. This can ofcourse always happen in Machine Learning, which is sometimes more of an art than a science. Several other methods to combat class imbalance could be checked for (oversampling, smote…), but an increase in performance is never guaruanteed.</p>
</section>
<section id="in-practice-mnist-dataset">
<h1>IN PRACTICE: MNIST DATASET<a class="headerlink" href="#in-practice-mnist-dataset" title="Permalink to this headline">#</a></h1>
<p>We will turn to a second problem: the classification of handwritten digits. This is a computer vision task, and we know that Logistic Regression and Random Forest are ill-equipped for this task. Instead, we will add a convolutional neural network to our pipeline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.datasets.mnist</span> <span class="kn">import</span> <span class="n">load_data</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">plot_model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.datasets.mnist</span> <span class="kn">import</span> <span class="n">load_data</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.wrappers.scikit_learn</span> <span class="kn">import</span> <span class="n">KerasClassifier</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Conv2D</span><span class="p">,</span> 
    <span class="n">Dense</span><span class="p">,</span> 
    <span class="n">Dropout</span><span class="p">,</span> 
    <span class="n">Flatten</span><span class="p">,</span> 
    <span class="n">MaxPool2D</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">X_digits_train</span><span class="p">,</span> <span class="n">y_digits_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_digits_test</span><span class="p">,</span> <span class="n">y_digits_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz

    8192/11490434 [..............................] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
  491520/11490434 [&gt;.............................] - ETA: 1s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 1064960/11490434 [=&gt;............................] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 1654784/11490434 [===&gt;..........................] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 2244608/11490434 [====&gt;.........................] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 2834432/11490434 [======&gt;.......................] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 3424256/11490434 [=======&gt;......................] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 4014080/11490434 [=========&gt;....................] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 4603904/11490434 [===========&gt;..................] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 5193728/11490434 [============&gt;.................] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 5783552/11490434 [==============&gt;...............] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 6373376/11490434 [===============&gt;..............] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 6963200/11490434 [=================&gt;............] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 7553024/11490434 [==================&gt;...........] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 8142848/11490434 [====================&gt;.........] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 8732672/11490434 [=====================&gt;........] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 9322496/11490434 [=======================&gt;......] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 9912320/11490434 [========================&gt;.....] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
10502144/11490434 [==========================&gt;...] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
11091968/11490434 [===========================&gt;..] - ETA: 0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
11493376/11490434 [==============================] - 1s 0us/step
</pre></div>
</div>
</div>
</div>
<p>So what does our data look like?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_digits_train</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_digits_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(60000, 28, 28)
</pre></div>
</div>
</div>
</div>
<p>So it is important to understand that this dataset is fundamentally different than the datasets that we have seen so far. Before we were seeing N * P datasets, where N is the number of data points and P is the number of features. Our current dataset is N * H * W. N is still the number of data points, but H refers to the height of the image and W to its width. Every cell in this array has a number attached to it to determine its colour (0 = black).</p>
<p>Let’s see if we can plot some images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span> <span class="c1"># specifying the overall grid size</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>    <span class="c1"># the number of images in the grid is 5*5 (25)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_digits_train</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/data_pipelines_64_0.png" src="../../_images/data_pipelines_64_0.png" />
</div>
</div>
<p>So the task is clear. We have these handwritten numbers and we will see if we can classify them correctly.</p>
<p>The models that we have seen so far, dont do good job on data like this. They do well on somewhat independent features, not on images with strong local correlations. We will, however, compare their (LR, RF..) performance to our new convolutional neural network.</p>
<p>To create our conv. neural network, we will turn to a library called <code class="docutils literal notranslate"><span class="pre">tensorflow/Keras</span></code>. For your understanding: Tensorflow is an ML/AI library that is optimized for mathematical operations. Keras is a library that runs on top of Tensorflow and does Deep Learning/Neural Networks.  This library allows us to completely customize our neural network to our needs. A proper introduction to Tensorflow is outside the scope of this course, but in practice we stack layers after each other. The final layer returns 10 values, with a probability for each possible output (the number 0 up to 10).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># defining the model</span>
<span class="n">inp_shape</span> <span class="o">=</span> <span class="n">X_digits_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="k">def</span> <span class="nf">create_model</span><span class="p">():</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">inp_shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">48</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<p>We wrap our model in KerasClassifier and then add it to our models_to_run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nn_clasifier</span> <span class="o">=</span> <span class="n">KerasClassifier</span><span class="p">(</span><span class="n">build_fn</span><span class="o">=</span><span class="n">create_model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">models_to_run</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span>
    <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span>
    <span class="n">nn_clasifier</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Our convolutional network is able to handle images, but the other models cannot. These models expect a N * P input (two dimensions) and not a N * H * W input (three dimensions). For those models we will average over the third dimension to get to our N * P format. We will, ofcourse, lose information in the process.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create ColumnTransformer, and pass the column names to transform in each step</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span>

<span class="k">def</span> <span class="nf">mean_over_second_image_dimension</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">transformer</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">mean_over_second_image_dimension</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">make_pipeline_mnist</span><span class="p">(</span><span class="n">classifier</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">()):</span>

    <span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
        <span class="n">steps</span><span class="o">=</span><span class="p">[</span>
            <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># check if instance is KerasClassifier, if not, add first steo to reduce</span>
    <span class="c1"># the dimensions</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">KerasClassifier</span><span class="p">):</span>
        <span class="n">clf</span><span class="o">.</span><span class="n">steps</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;estimator&#39;</span><span class="p">,</span> <span class="n">transformer</span><span class="p">])</span> <span class="c1">#insert as first step</span>


    <span class="k">return</span> <span class="n">clf</span>
</pre></div>
</div>
</div>
</div>
<p>Lets run the pipelines again and store our results</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models_to_run</span><span class="p">:</span>
    <span class="c1"># create instance of the class, feed the model to be tested</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">make_pipeline_mnist</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_digits_train</span><span class="p">,</span> <span class="n">y_digits_train</span><span class="p">)</span>

    <span class="c1"># store results in a dictionary </span>
    <span class="n">results</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="p">)]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_digits_test</span><span class="p">,</span> <span class="n">y_digits_test</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/jan/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-10-17 17:28:19.645414: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-17 17:28:19.710545: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-10-17 17:28:19.728630: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3609600000 Hz
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span> <span class="p">[</span><span class="mi">31</span><span class="p">],</span> <span class="n">line</span> <span class="mi">5</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models_to_run</span><span class="p">:</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>     <span class="c1"># create instance of the class, feed the model to be tested</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>     <span class="n">clf</span> <span class="o">=</span> <span class="n">make_pipeline_mnist</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">5</span>     <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_digits_train</span><span class="p">,</span> <span class="n">y_digits_train</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>     <span class="c1"># store results in a dictionary </span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>     <span class="n">results</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="p">)]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_digits_test</span><span class="p">,</span> <span class="n">y_digits_test</span><span class="p">)</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/sklearn/pipeline.py:382,</span> in <span class="ni">Pipeline.fit</span><span class="nt">(self, X, y, **fit_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">380</span>     <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_estimator</span> <span class="o">!=</span> <span class="s2">&quot;passthrough&quot;</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">381</span>         <span class="n">fit_params_last_step</span> <span class="o">=</span> <span class="n">fit_params_steps</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span>
<span class="ne">--&gt; </span><span class="mi">382</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_final_estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xt</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params_last_step</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">384</span> <span class="k">return</span> <span class="bp">self</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:223,</span> in <span class="ni">KerasClassifier.fit</span><span class="nt">(self, x, y, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">221</span>   <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid shape for y: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">222</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_classes_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">223</span> <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">KerasClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:166,</span> in <span class="ni">BaseWrapper.fit</span><span class="nt">(self, x, y, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">163</span> <span class="n">fit_args</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_sk_params</span><span class="p">(</span><span class="n">Sequential</span><span class="o">.</span><span class="n">fit</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">164</span> <span class="n">fit_args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">166</span> <span class="n">history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_args</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">168</span> <span class="k">return</span> <span class="n">history</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1095,</span> in <span class="ni">Model.fit</span><span class="nt">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="g g-Whitespace">   </span><span class="mi">1088</span> <span class="k">with</span> <span class="n">trace</span><span class="o">.</span><span class="n">Trace</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1089</span>     <span class="s1">&#39;train&#39;</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1090</span>     <span class="n">epoch_num</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1091</span>     <span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1092</span>     <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1093</span>     <span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1094</span>   <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1095</span>   <span class="n">tmp_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1096</span>   <span class="k">if</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1097</span>     <span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828,</span> in <span class="ni">Function.__call__</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">826</span> <span class="n">tracing_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experimental_get_tracing_count</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">827</span> <span class="k">with</span> <span class="n">trace</span><span class="o">.</span><span class="n">Trace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span> <span class="k">as</span> <span class="n">tm</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">828</span>   <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">829</span>   <span class="n">compiler</span> <span class="o">=</span> <span class="s2">&quot;xla&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experimental_compile</span> <span class="k">else</span> <span class="s2">&quot;nonXla&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">830</span>   <span class="n">new_tracing_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experimental_get_tracing_count</span><span class="p">()</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:871,</span> in <span class="ni">Function._call</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">868</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">869</span>   <span class="c1"># This is the first call of __call__, so we have to initialize.</span>
<span class="g g-Whitespace">    </span><span class="mi">870</span>   <span class="n">initializers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="ne">--&gt; </span><span class="mi">871</span>   <span class="bp">self</span><span class="o">.</span><span class="n">_initialize</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwds</span><span class="p">,</span> <span class="n">add_initializers_to</span><span class="o">=</span><span class="n">initializers</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">872</span> <span class="k">finally</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">873</span>   <span class="c1"># At this point we know that the initialization is complete (or less</span>
<span class="g g-Whitespace">    </span><span class="mi">874</span>   <span class="c1"># interestingly an exception was raised) so we no longer need a lock.</span>
<span class="g g-Whitespace">    </span><span class="mi">875</span>   <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:725,</span> in <span class="ni">Function._initialize</span><span class="nt">(self, args, kwds, add_initializers_to)</span>
<span class="g g-Whitespace">    </span><span class="mi">722</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lifted_initializer_graph</span> <span class="o">=</span> <span class="n">lifted_initializer_graph</span>
<span class="g g-Whitespace">    </span><span class="mi">723</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph_deleter</span> <span class="o">=</span> <span class="n">FunctionDeleter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_lifted_initializer_graph</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">724</span> <span class="bp">self</span><span class="o">.</span><span class="n">_concrete_stateful_fn</span> <span class="o">=</span> <span class="p">(</span>
<span class="ne">--&gt; </span><span class="mi">725</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_stateful_fn</span><span class="o">.</span><span class="n">_get_concrete_function_internal_garbage_collected</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
<span class="g g-Whitespace">    </span><span class="mi">726</span>         <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">728</span> <span class="k">def</span> <span class="nf">invalid_creator_scope</span><span class="p">(</span><span class="o">*</span><span class="n">unused_args</span><span class="p">,</span> <span class="o">**</span><span class="n">unused_kwds</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">729</span>   <span class="sd">&quot;&quot;&quot;Disables variable creation.&quot;&quot;&quot;</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2969,</span> in <span class="ni">Function._get_concrete_function_internal_garbage_collected</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">2967</span>   <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
<span class="g g-Whitespace">   </span><span class="mi">2968</span> <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">2969</span>   <span class="n">graph_function</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_define_function</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2970</span> <span class="k">return</span> <span class="n">graph_function</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3361,</span> in <span class="ni">Function._maybe_define_function</span><span class="nt">(self, args, kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">3357</span>   <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_define_function_with_shape_relaxation</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">3358</span>       <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">flat_args</span><span class="p">,</span> <span class="n">filtered_flat_args</span><span class="p">,</span> <span class="n">cache_key_context</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">3360</span> <span class="bp">self</span><span class="o">.</span><span class="n">_function_cache</span><span class="o">.</span><span class="n">missed</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">call_context_key</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">3361</span> <span class="n">graph_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_graph_function</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">3362</span> <span class="bp">self</span><span class="o">.</span><span class="n">_function_cache</span><span class="o">.</span><span class="n">primary</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">graph_function</span>
<span class="g g-Whitespace">   </span><span class="mi">3364</span> <span class="k">return</span> <span class="n">graph_function</span><span class="p">,</span> <span class="n">filtered_flat_args</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3196,</span> in <span class="ni">Function._create_graph_function</span><span class="nt">(self, args, kwargs, override_flat_arg_shapes)</span>
<span class="g g-Whitespace">   </span><span class="mi">3191</span> <span class="n">missing_arg_names</span> <span class="o">=</span> <span class="p">[</span>
<span class="nn">   3192     &quot;%s_%d&quot; % (arg, i) for i, arg</span> in <span class="ni">enumerate</span><span class="nt">(missing_arg_names)</span>
<span class="g g-Whitespace">   </span><span class="mi">3193</span> <span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">3194</span> <span class="n">arg_names</span> <span class="o">=</span> <span class="n">base_arg_names</span> <span class="o">+</span> <span class="n">missing_arg_names</span>
<span class="g g-Whitespace">   </span><span class="mi">3195</span> <span class="n">graph_function</span> <span class="o">=</span> <span class="n">ConcreteFunction</span><span class="p">(</span>
<span class="ne">-&gt; </span><span class="mi">3196</span>     <span class="n">func_graph_module</span><span class="o">.</span><span class="n">func_graph_from_py_func</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">3197</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3198</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_python_function</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3199</span>         <span class="n">args</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3200</span>         <span class="n">kwargs</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3201</span>         <span class="bp">self</span><span class="o">.</span><span class="n">input_signature</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3202</span>         <span class="n">autograph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_autograph</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3203</span>         <span class="n">autograph_options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_autograph_options</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3204</span>         <span class="n">arg_names</span><span class="o">=</span><span class="n">arg_names</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3205</span>         <span class="n">override_flat_arg_shapes</span><span class="o">=</span><span class="n">override_flat_arg_shapes</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3206</span>         <span class="n">capture_by_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_capture_by_value</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">3207</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_function_attributes</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3208</span>     <span class="n">function_spec</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">function_spec</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3209</span>     <span class="c1"># Tell the ConcreteFunction to clean up its graph once it goes out of</span>
<span class="g g-Whitespace">   </span><span class="mi">3210</span>     <span class="c1"># scope. This is not the default behavior since it gets used in some</span>
<span class="g g-Whitespace">   </span><span class="mi">3211</span>     <span class="c1"># places (like Keras) where the FuncGraph lives longer than the</span>
<span class="g g-Whitespace">   </span><span class="mi">3212</span>     <span class="c1"># ConcreteFunction.</span>
<span class="g g-Whitespace">   </span><span class="mi">3213</span>     <span class="n">shared_func_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">3214</span> <span class="k">return</span> <span class="n">graph_function</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:990,</span> in <span class="ni">func_graph_from_py_func</span><span class="nt">(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)</span>
<span class="g g-Whitespace">    </span><span class="mi">987</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">988</span>   <span class="n">_</span><span class="p">,</span> <span class="n">original_func</span> <span class="o">=</span> <span class="n">tf_decorator</span><span class="o">.</span><span class="n">unwrap</span><span class="p">(</span><span class="n">python_func</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">990</span> <span class="n">func_outputs</span> <span class="o">=</span> <span class="n">python_func</span><span class="p">(</span><span class="o">*</span><span class="n">func_args</span><span class="p">,</span> <span class="o">**</span><span class="n">func_kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">992</span> <span class="c1"># invariant: `func_outputs` contains only Tensors, CompositeTensors,</span>
<span class="g g-Whitespace">    </span><span class="mi">993</span> <span class="c1"># TensorArrays and `None`s.</span>
<span class="g g-Whitespace">    </span><span class="mi">994</span> <span class="n">func_outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">convert</span><span class="p">,</span> <span class="n">func_outputs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">995</span>                                   <span class="n">expand_composites</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:634,</span> in <span class="ni">Function._defun_with_scope.&lt;locals&gt;.wrapped_fn</span><span class="nt">(*args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">632</span>     <span class="n">xla_context</span><span class="o">.</span><span class="n">Exit</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">633</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">634</span>   <span class="n">out</span> <span class="o">=</span> <span class="n">weak_wrapped_fn</span><span class="p">()</span><span class="o">.</span><span class="n">__wrapped__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">635</span> <span class="k">return</span> <span class="n">out</span>

<span class="nn">File ~/miniconda3/envs/ds-academy-development/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:977,</span> in <span class="ni">func_graph_from_py_func.&lt;locals&gt;.wrapper</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">975</span> <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>  <span class="c1"># pylint:disable=broad-except</span>
<span class="g g-Whitespace">    </span><span class="mi">976</span>   <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="s2">&quot;ag_error_metadata&quot;</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">977</span>     <span class="k">raise</span> <span class="n">e</span><span class="o">.</span><span class="n">ag_error_metadata</span><span class="o">.</span><span class="n">to_exception</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">978</span>   <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">979</span>     <span class="k">raise</span>

<span class="ne">ValueError</span>: in user code:

    <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">jan</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">ds</span><span class="o">-</span><span class="n">academy</span><span class="o">-</span><span class="n">development</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.9</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">keras</span><span class="o">/</span><span class="n">engine</span><span class="o">/</span><span class="n">training</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">800</span> <span class="n">train_function</span>  <span class="o">*</span>
        <span class="k">return</span> <span class="n">step_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>
    <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">jan</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">ds</span><span class="o">-</span><span class="n">academy</span><span class="o">-</span><span class="n">development</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.9</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">keras</span><span class="o">/</span><span class="n">engine</span><span class="o">/</span><span class="n">training</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">790</span> <span class="n">step_function</span>  <span class="o">**</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">data</span><span class="p">,))</span>
    <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">jan</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">ds</span><span class="o">-</span><span class="n">academy</span><span class="o">-</span><span class="n">development</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.9</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">distribute</span><span class="o">/</span><span class="n">distribute_lib</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">1259</span> <span class="n">run</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extended</span><span class="o">.</span><span class="n">call_for_each_replica</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">jan</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">ds</span><span class="o">-</span><span class="n">academy</span><span class="o">-</span><span class="n">development</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.9</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">distribute</span><span class="o">/</span><span class="n">distribute_lib</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">2730</span> <span class="n">call_for_each_replica</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_for_each_replica</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
    <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">jan</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">ds</span><span class="o">-</span><span class="n">academy</span><span class="o">-</span><span class="n">development</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.9</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">distribute</span><span class="o">/</span><span class="n">distribute_lib</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">3417</span> <span class="n">_call_for_each_replica</span>
        <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">jan</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">ds</span><span class="o">-</span><span class="n">academy</span><span class="o">-</span><span class="n">development</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.9</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">keras</span><span class="o">/</span><span class="n">engine</span><span class="o">/</span><span class="n">training</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">783</span> <span class="n">run_step</span>  <span class="o">**</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">jan</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">ds</span><span class="o">-</span><span class="n">academy</span><span class="o">-</span><span class="n">development</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.9</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">keras</span><span class="o">/</span><span class="n">engine</span><span class="o">/</span><span class="n">training</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">749</span> <span class="n">train_step</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">jan</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">ds</span><span class="o">-</span><span class="n">academy</span><span class="o">-</span><span class="n">development</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.9</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">keras</span><span class="o">/</span><span class="n">engine</span><span class="o">/</span><span class="n">base_layer</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">998</span> <span class="fm">__call__</span>
        <span class="n">input_spec</span><span class="o">.</span><span class="n">assert_input_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">jan</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">ds</span><span class="o">-</span><span class="n">academy</span><span class="o">-</span><span class="n">development</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.9</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">keras</span><span class="o">/</span><span class="n">engine</span><span class="o">/</span><span class="n">input_spec</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">234</span> <span class="n">assert_input_compatibility</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Input &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">input_index</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; of layer &#39;</span> <span class="o">+</span>

    <span class="ne">ValueError</span><span class="p">:</span> <span class="n">Input</span> <span class="mi">0</span> <span class="n">of</span> <span class="n">layer</span> <span class="n">sequential</span> <span class="ow">is</span> <span class="n">incompatible</span> <span class="k">with</span> <span class="n">the</span> <span class="n">layer</span><span class="p">:</span> <span class="p">:</span> <span class="n">expected</span> <span class="n">min_ndim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">found</span> <span class="n">ndim</span><span class="o">=</span><span class="mf">3.</span> <span class="n">Full</span> <span class="n">shape</span> <span class="n">received</span><span class="p">:</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As expected our convolutional network does a bitter job than the other algorithms! But, there are some tricks to upgrade their performances… see exercise!</p>
</section>
<section id="exercise-bonus-tutorial">
<h1>Exercise / bonus tutorial<a class="headerlink" href="#exercise-bonus-tutorial" title="Permalink to this headline">#</a></h1>
<p>Our previous method to reduce the dimensionality of the mnist inputs in order to prepare them for a Random Forest, is probably not the best. Instead of it, we will turn to a different approach.</p>
<p>In fact, we want to perform Dimensionality Reduction. This could also be achieved by the unsupervised ML-method of Principal Component Analysis (PCA). In this exercise, we will use this method to prepare our image data for a Random Forest.</p>
<ol class="simple">
<li><p>load PCA from sklearn</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
</pre></div>
</div>
</div>
</div>
<ol class="simple">
<li><p>Replace the mean_over_second_image_dimension function by a reshape_image function. It should use np.reshape() and replace the 28 x 28 format by the 728 x 1 format.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create ColumnTransformer, and pass the column names to transform in each step</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span>

<span class="c1"># def mean_over_second_image_dimension(img):</span>
<span class="c1">#     return np.mean(img, axis=2)</span>

<span class="k">def</span> <span class="nf">reshape_image</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    
    <span class="c1"># Your code here</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>  <span class="n">Input</span> <span class="n">In</span> <span class="p">[</span><span class="mi">33</span><span class="p">]</span>
    <span class="c1"># Your code here</span>
                    <span class="o">^</span>
<span class="ne">IndentationError</span>: expected an indented block
</pre></div>
</div>
</div>
</div>
<ol class="simple">
<li><p>Add both the transformation step from the previous cell, and PCA to the pipeline below. For PCA, use the parameter n_components=20.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_pipeline_mnist</span><span class="p">(</span><span class="n">classifier</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">()):</span>

    <span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
        <span class="n">steps</span><span class="o">=</span><span class="p">[</span>
            <span class="p">(</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># check if instance is KerasClassifier, if not, add first steo to reduce</span>
    <span class="c1"># the dimensions</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">KerasClassifier</span><span class="p">):</span>
        
        <span class="c1"># your code here</span>


    <span class="k">return</span> <span class="n">clf</span>
</pre></div>
</div>
</div>
</div>
<ol class="simple">
<li><p>Run the new pipeline on all the previous models.</p></li>
</ol>
<ol class="simple">
<li><p>What is the upgrade in performance? ;-)</p></li>
</ol>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lectures/04_lecture"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Let’s build our first data pipeline!</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../05_lecture/intro.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Evaluating, comparing, and selecting ML models</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By STRV, Data Science Department<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>